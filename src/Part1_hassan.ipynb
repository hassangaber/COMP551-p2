{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a00ee38e",
   "metadata": {},
   "source": [
    "# Part 1\n",
    "\n",
    "## These are just preliminary tests for now (10/10/2021 4pm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b19e154",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "# Importing standard modules\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score\n",
    "import lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "8f84598b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('../data/diabetes/diabetes_train.csv')\n",
    "test = pd.read_csv('../data/diabetes/diabetes_test.csv')\n",
    "valid = pd.read_csv('../data/diabetes/diabetes_val.csv')\n",
    "all_data = pd.concat([train, test, valid], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ec35b11",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Test run with logistic regression model\n",
    "trainX=train.drop('Outcome',axis=1)\n",
    "trainY=train['Outcome']\n",
    "\n",
    "X=trainX.to_numpy()\n",
    "Y=trainY.to_numpy()\n",
    "\n",
    "model = lr.LogisticRegression(verbose=True, )\n",
    "yh = model.fit(X,Y).predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e2b0bcf",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Function to find convergent solution of gradient descent as a function of learning-rate and maximum iterations\n",
    "\n",
    "def optimize(max_iter, learning_rate, pred_data):\n",
    "    \n",
    "    # Input data, features and binary labels column\n",
    "    Xin = train.drop('Outcome',axis=1).to_numpy()\n",
    "    Yin = train['Outcome'].to_numpy()\n",
    "    \n",
    "    # Prediction data, validation set\n",
    "    Xp = pred_data.drop('Outcome',axis=1).to_numpy()\n",
    "    Yp = pred_data['Outcome'].to_numpy().ravel()\n",
    "    \n",
    "    # For later use when determining accuracy\n",
    "    T = []\n",
    "    \n",
    "    # Iterate through the input parameters\n",
    "    for l in learning_rate:\n",
    "        print(f'LEARNING RATE: {l} \\n')\n",
    "        for m in max_iter:\n",
    "            #print(\"MAX ITERATIONS: \", m)\n",
    "            model = lr.LogisticRegression(verbose=True, add_bias=True, learning_rate=l, max_iters=m)\n",
    "            yh = model.fit(Xin,Yin).predict(Xin)\n",
    "            T.append(yh)\n",
    "        \n",
    "        \n",
    "    #print(accuracy_score(T,Yp[:4]))\n",
    "    \n",
    "mi = [9e6]\n",
    "learn = [0.00005, 0.000075]\n",
    "\n",
    "optimize(max_iter=mi, learning_rate=learn, pred_data=valid)  "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
