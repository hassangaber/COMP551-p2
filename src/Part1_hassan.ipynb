{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a00ee38e",
   "metadata": {},
   "source": [
    "# Part 1.1 - Optimizing test accuracy as a function of learning rate and maximum iterations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0b19e154",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Importing standard modules\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "import lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8f84598b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('../data/diabetes/diabetes_train.csv')\n",
    "test = pd.read_csv('../data/diabetes/diabetes_test.csv')\n",
    "valid = pd.read_csv('../data/diabetes/diabetes_val.csv')\n",
    "all_data = pd.concat([train, test, valid], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1e2b0bcf",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Function to find convergent solution of gradient descent as a function of learning-rate and maximum iterations\n",
    "\n",
    "def optimize(max_iter, learning_rate, pred_data):\n",
    "    \n",
    "    # Input data, features and binary labels column\n",
    "    Xin = train.drop('Outcome',axis=1).to_numpy()\n",
    "    Yin = train['Outcome'].to_numpy()\n",
    "    \n",
    "    # Prediction data, validation set\n",
    "    Xp = pred_data.drop('Outcome',axis=1).to_numpy()\n",
    "    Yp = pred_data['Outcome'].to_numpy().ravel()\n",
    "    \n",
    "    # Iterate through the input parameters\n",
    "    for l in learning_rate:\n",
    "        \n",
    "        for m in max_iter:\n",
    "            \n",
    "            #print(\"MAX ITERATIONS: \", m)\n",
    "            print(f'LEARNING RATE: {l} \\n')\n",
    "            model = lr.LogisticRegression(verbose=True, add_bias=True, learning_rate=l, max_iters=m)\n",
    "            yh = model.fit(Xin,Yin).predict(Xp)\n",
    "            T = []\n",
    "            T.append(yh)\n",
    "        \n",
    "            # Decision Boundary\n",
    "            prediction = []\n",
    "            for x in np.array(T).ravel():\n",
    "                if x < 0.5: prediction.append(0)\n",
    "                else: prediction.append(1)\n",
    "\n",
    "            #print(T)\n",
    "            #print(prediction)\n",
    "            #print(Yp)\n",
    "            print(\"Accuracy Score:\", accuracy_score(Yp,np.array(prediction).ravel()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e418286",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Best set of parameters so far:\n",
    "m = [1e6, 5e6]\n",
    "l = [2e-4, 5e-4]\n",
    "\n",
    "optimize(max_iter=m, learning_rate=l, pred_data=test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1f941720",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function determines the accuracy the Sklearn logisitic classifier can achieve\n",
    "\n",
    "def compareSK(pred_data):\n",
    "    \n",
    "    # Input data, features and binary labels column\n",
    "    Xin = train.drop('Outcome',axis=1).to_numpy()\n",
    "    Yin = train['Outcome'].to_numpy()\n",
    "    \n",
    "    # Prediction data, validation set\n",
    "    Xp = pred_data.drop('Outcome',axis=1).to_numpy()\n",
    "    Yp = pred_data['Outcome'].to_numpy().ravel()\n",
    "    \n",
    "    model = SGDClassifier(max_iter=9e6, alpha=0.0002)\n",
    "    yh = model.fit(Xin,Yin).predict(Xp)\n",
    "    \n",
    "    T = []\n",
    "    T.append(yh)\n",
    "    print(T)\n",
    "    \n",
    "    # Decision Boundary\n",
    "    prediction = []\n",
    "    for x in np.array(T).ravel():\n",
    "        if x < 0.5: prediction.append(0)\n",
    "        else: prediction.append(1)\n",
    "            \n",
    "    print(Yp)\n",
    "    \n",
    "    print(\"Accuracy Score:\", accuracy_score(Yp,np.array(prediction).ravel()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "168c779f",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 1,\n",
      "       1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0,\n",
      "       1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1,\n",
      "       1, 1])]\n",
      "[0 0 1 0 0 0 0 1 0 1 0 1 0 0 0 0 1 0 0 0 0 0 0 1 1 1 0 0 1 0 0 0 0 0 0 0 0\n",
      " 0 0 1 1 1 0 0 0 0 0 0 0 1 0 1 0 0 1 0 0 0 0 1 0 0 1 0 1 1 0 1]\n",
      "Accuracy Score: 0.6764705882352942\n"
     ]
    }
   ],
   "source": [
    "compareSK(pred_data=test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdb6558c",
   "metadata": {},
   "source": [
    "## Results & Remarks\n",
    "\n",
    "* Our base model preformed better than the Sklearn SGD logisitic classifier with a margin greater than 10%\n",
    "\n",
    "* Decision Boundary is set at X=0.5: $$P(y=1|X) < 0.5 \\rightarrow \\hat{y}=0$$ $$P(y=1|X) \\geq 0.5 \\rightarrow \\hat{y}= 1$$ \n",
    "\n",
    "\n",
    "* Best accuracy achieved on the test set was 77.9% with $\\alpha = 2 * 10^{-4}$ and $i_{max} = 1 * 10^6$\n",
    "\n",
    "* Output (including weights and magnitude of gradient vector):\n",
    "\n",
    "```\n",
    "                    LEARNING RATE: 2e-4\n",
    "                    \n",
    "                    1000000 Iterations\n",
    "                    Norm of gradient: 0.013429351710347736\n",
    "\n",
    "                    Weights: [ 1.29152029e-01  2.50264215e-02 -1.86834650e-02 -2.52562870e-03\n",
    "                      4.12691159e-04  4.13164885e-02  5.23867127e-01  6.70382786e-04\n",
    "                     -4.46242101e+00]\n",
    "\n",
    "                    Accuracy Score: 0.7794117647058824\n",
    "                    \n",
    "                    -----------------------------------------------------------------------------\n",
    "                    \n",
    "                    LEARNING RATE: 9e-05 \n",
    "\n",
    "                    5000000 Iterations\n",
    "                    Norm of gradient: 0.005435090157130823\n",
    "\n",
    "                    Weights: [ 1.36309194e-01  3.11128368e-02 -1.48346749e-02 -3.04513818e-03\n",
    "                     -8.58120779e-05  6.64128026e-02  7.09122848e-01  6.22651319e-03\n",
    "                     -6.61628338e+00]\n",
    "\n",
    "                    Accuracy Score: 0.7794117647058824\n",
    "```"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
