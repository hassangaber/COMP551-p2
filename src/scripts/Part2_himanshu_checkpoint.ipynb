{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.linear_model import LogisticRegressionCV\n",
    "from sklearn import metrics\n",
    "from nltk import word_tokenize, sent_tokenize\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import re"
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Tested for stop words, removing stopwords made the model worse.\n",
    "\n",
    "using bigrams increases efficiency by a little, not much, but takes much longer time. might be better not to use it if efficiency is not great\n",
    "\n",
    "- Increases efficiecny from 66.8 to 68.7\n",
    "\n",
    "Now checking whether token_regex thing is better or using strip accesnts ascii is better, or using both is better.\n",
    "\n",
    "After looking at feature names, I concluded that maybe using numbers might not be a good decision.\n",
    "Will have to test the model by removing numbers or keeping them. what is the best way of removing numbers?\n",
    "\n",
    "\n",
    "- using ascii gave us an increase from 68.7 to 69.15 with bigrams\n",
    "- without bigrams it actually dropped from 66.8 to 66.45\n",
    "- Using both ascii and regex without bigrams made it even worse to 66.4\n",
    "- Using both dropped accuracy to 68.45\n",
    "- Now testing none with bigrams: This gives me a 69.6 accuracy\n",
    "- Then test a different token that completely gets rid of tokens with numbers in them\n",
    "   - using  r'\\b[^\\d\\W]+\\b' which only selects alphanumeric words with underscores, accuracy was 68.7\n",
    "   - using r'\\b[^\\d\\W_]+\\b' gives me 68.65\n",
    "   - using min length 3 gave me 67.55\n",
    "   - using min length 2 gave me 68.55\n",
    "   - using r\"\\b[^\\d\\W]+\\b|\\b[0-9]+\\b\" as the token patter gave me an accuracy of 70.1 which is the best by far\n",
    "   - Using the CountVectorizer gave much better accuracy than TfidfVectorizer - 61.5\n",
    "\n",
    "testing on hyper-params: max_df and min_df\n",
    "- max_df best is 1.0 itself (that is keeping in all words)\n",
    "- min_df is also best at default. but at 3 gives 78.7. at 2 gives 78.35\n",
    "\n",
    "Considerations of stemming and lemmatization\n",
    "- stemming\n",
    "- lemmatization\n",
    "\n",
    "This is a 3% difference which is significant, hence maybe certain decisions imrpove the efficiency of bigrams.\n",
    "\n",
    "checking sklearn and nltk: answer - create our own preprocessor for the CV.\n",
    "\n",
    "Other decisions to consider:\n",
    "Lower case everything or not? might miss importance of names if we convert to lower case\n",
    "Consider removing all non-english characters\n",
    "\n",
    "# Running LogisticRegressionCV\n",
    "\n",
    "- With default setting (Cs=10 chosen between 1e-4 and 1e4)\n",
    "\n",
    "Cs: array([1.00000000e-04, 7.74263683e-04, 5.99484250e-03, 4.64158883e-02,\n",
    "       3.59381366e-01, 2.78255940e+00, 2.15443469e+01, 1.66810054e+02,\n",
    "       1.29154967e+03, 1.00000000e+04])\n",
    "\n",
    "Mean scores:\n",
    "0    0.67795\n",
    "1    0.73440\n",
    "2    0.76475\n",
    "3    0.76935\n",
    "4    0.76600\n",
    "5    0.76510\n",
    "6    0.76380\n",
    "7    0.76205\n",
    "8    0.76130\n",
    "9    0.76075\n",
    "\n",
    "Max scores:\n",
    "0    0.68450\n",
    "1    0.74275\n",
    "2    0.77175\n",
    "3    0.78100\n",
    "4    0.77900\n",
    "5    0.78175\n",
    "6    0.77950\n",
    "7    0.77725\n",
    "8    0.77675\n",
    "9    0.77625\n",
    "\n",
    "scores:\n",
    "\n",
    "{1: array([[0.6785 , 0.72975, 0.76425, 0.7695 , 0.763  , 0.76   , 0.76   ,\n",
    "         0.7595 , 0.759  , 0.7575 ],\n",
    "        [0.68275, 0.73125, 0.76075, 0.7695 , 0.76575, 0.76725, 0.76425,\n",
    "         0.76275, 0.762  , 0.762  ],\n",
    "        [0.669  , 0.73175, 0.757  , 0.75625, 0.7545 , 0.7515 , 0.75125,\n",
    "         0.74775, 0.7475 , 0.7475 ],\n",
    "        [0.6845 , 0.74275, 0.77175, 0.781  , 0.779  , 0.78175, 0.7795 ,\n",
    "         0.77725, 0.77675, 0.77625],\n",
    "        [0.675  , 0.7365 , 0.77   , 0.7705 , 0.76775, 0.765  , 0.764  ,\n",
    "         0.763  , 0.76125, 0.7605 ]])}\n",
    "\n",
    "We know from previous tests that the accuracy when Cs = 1.0 is 78.7.\n",
    "\n",
    "Hence peaking around there, now test on Cs values around 1.0.\n",
    "\n",
    "78.4 accuracy on unseen data (when tested on validation set not used in CV)\n",
    "\n",
    "- Cs=[0.01, 0.5, 0.75, 1.0, 1.25, 1.5, 2.0]\n",
    "\n",
    "scores\n",
    "\n",
    "\n",
    "{1: array([[0.76775, 0.76225, 0.7625 , 0.762  , 0.76175, 0.761  , 0.76025],\n",
    "        [0.76825, 0.76625, 0.76575, 0.76725, 0.76725, 0.7675 , 0.76675],\n",
    "        [0.75675, 0.7545 , 0.75325, 0.753  , 0.75275, 0.752  , 0.75175],\n",
    "        [0.7755 , 0.77775, 0.7775 , 0.778  , 0.78   , 0.78   , 0.78075],\n",
    "        [0.773  , 0.76775, 0.76775, 0.76725, 0.7665 , 0.76525, 0.76525]])}\n",
    "\n",
    "\n",
    "Mean:\n",
    "\n",
    "0    0.76825\n",
    "1    0.76570\n",
    "2    0.76535\n",
    "3    0.76550\n",
    "4    0.76565\n",
    "5    0.76515\n",
    "6    0.76495\n",
    "\n",
    "Max:\n",
    "0    0.77550\n",
    "1    0.77775\n",
    "2    0.77750\n",
    "3    0.77800\n",
    "4    0.78000\n",
    "5    0.78000\n",
    "6    0.78075\n",
    "\n",
    "77.95 accuracy on unseen data.\n",
    "\n",
    "- Now seeing as the highest mean was at 0.01 [1.00e-02, 4.00e-02, 7.00e-02, 9.00e-02]\n",
    "\n",
    "scores:\n",
    "\n",
    "{1: array([[0.76775, 0.769  , 0.76875, 0.76875],\n",
    "        [0.76825, 0.77   , 0.76775, 0.76725],\n",
    "        [0.75675, 0.758  , 0.75375, 0.75475],\n",
    "        [0.7755 , 0.7805 , 0.78025, 0.7815 ],\n",
    "        [0.773  , 0.76975, 0.76975, 0.76875]])}\n",
    "\n",
    "\n",
    "Mean:\n",
    "0    0.76825\n",
    "1    0.76945\n",
    "2    0.76805\n",
    "3    0.76820\n",
    "\n",
    "Max:\n",
    "0    0.77550\n",
    "1    0.78050\n",
    "2    0.78025\n",
    "3    0.78150\n",
    "\n",
    "Accuracy on unseen data was 78.6%\n",
    "\n",
    "-Now finally tuning on a good peak value of 4.00e-02 [3.50e-02, 3.75e-02, 4.00e-02, 4.25e-02, 4.50e-02]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer(ngram_range=(1, 2), token_pattern=r\"\\b[^\\d\\W]+\\b|\\b[0-9]+\\b\", min_df=3)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "outputs": [],
   "source": [
    "#pattern = re.compile(r'\\b[^\\d\\W]+\\b|\\b[0-9]+\\b')"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "outputs": [
    {
     "data": {
      "text/plain": "0    Indian fruit is so important to so many people...\n1    FORT WORTH, Texas — Urú Inc. will hold a confe...\n2    With three of the four new carriers, the Niger...\n3    Let's start with the classic annual dividend r...\n4    Following are some of the major events to have...\n5    Posted\\nAn empty classroom in rural communitie...\n6    The whales we know today look nothing like the...\n7    Local news anchor Richard Ray announced Thursd...\n8    PROVO — In the 17 years that he’s been married...\n9    Before a crowd of 4,000 people, Sen. Cory Book...\nName: text, dtype: object"
     },
     "execution_count": 138,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fake_news_training = pd.read_csv('../data/fake_news/fake_news_train.csv')\n",
    "fake_news_validation = pd.read_csv('../data/fake_news/fake_news_val.csv')\n",
    "fake_news_training['text'][:10]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "outputs": [],
   "source": [
    "#lemmatizer = WordNetLemmatizer()\n",
    "#fake_news_training['text'] = fake_news_training['text'].apply(lambda corpus: ' '.join(' '.join([lemmatizer.lemmatize(word.lower()) for word in word_tokenize(sent) if word.isalpha()]) for sent in sent_tokenize(corpus)))\n",
    "#fake_news_training['text'][:10]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "outputs": [],
   "source": [
    "#fake_news_validation['text'] = fake_news_validation['text'].apply(lambda corpus: ' '.join(' '.join([lemmatizer.lemmatize(word.lower()) for word in word_tokenize(sent) if word.isalpha()]) for sent in sent_tokenize(corpus)))\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "outputs": [
    {
     "data": {
      "text/plain": "CountVectorizer(min_df=3, ngram_range=(1, 2),\n                token_pattern='\\\\b[^\\\\d\\\\W]+\\\\b|\\\\b[0-9]+\\\\b')"
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer.fit(fake_news_training['text'])\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "outputs": [
    {
     "data": {
      "text/plain": "array(['0', '0 0', '0 00', ..., 'únicos', 'œwe', 'œwe are'], dtype=object)"
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vectorizer.get_feature_names_out()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "outputs": [
    {
     "data": {
      "text/plain": "472940"
     },
     "execution_count": 143,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(vectorizer.get_feature_names_out())"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "outputs": [
    {
     "data": {
      "text/plain": "LogisticRegressionCV(Cs=[0.01, 0.04, 0.07, 0.09], max_iter=1000)"
     },
     "execution_count": 144,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "training_features = vectorizer.transform(fake_news_training['text'])\n",
    "validation_features = vectorizer.transform(fake_news_validation['text'])"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "outputs": [
    {
     "data": {
      "text/plain": "LogisticRegressionCV(Cs=[0.01, 0.04, 0.07, 0.09], max_iter=1000)"
     },
     "execution_count": 151,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = LogisticRegressionCV(max_iter=1000, Cs=[1.00e-02, 4.00e-02, 7.00e-02, 9.00e-02])\n",
    "clf.fit(training_features, fake_news_training['label'])\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "outputs": [
    {
     "data": {
      "text/plain": "0.786"
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = clf.predict(validation_features)\n",
    "y_valid = fake_news_validation['label']\n",
    "\n",
    "metrics.accuracy_score(y_valid, y_pred)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "outputs": [
    {
     "data": {
      "text/plain": "{1: array([[0.76775, 0.769  , 0.76875, 0.76875],\n        [0.76825, 0.77   , 0.76775, 0.76725],\n        [0.75675, 0.758  , 0.75375, 0.75475],\n        [0.7755 , 0.7805 , 0.78025, 0.7815 ],\n        [0.773  , 0.76975, 0.76975, 0.76875]])}"
     },
     "execution_count": 153,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.scores_"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "outputs": [
    {
     "data": {
      "text/plain": "array([0.01, 0.04, 0.07, 0.09])"
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf.Cs_"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "outputs": [
    {
     "data": {
      "text/plain": "0    0.77550\n1    0.78050\n2    0.78025\n3    0.78150\ndtype: float64"
     },
     "execution_count": 155,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CV = pd.DataFrame(data=clf.scores_[1])\n",
    "CV.max(axis=0)\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}