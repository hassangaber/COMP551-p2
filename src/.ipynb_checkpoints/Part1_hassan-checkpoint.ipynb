{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a00ee38e",
   "metadata": {},
   "source": [
    "# Part 1\n",
    "\n",
    "## These are just preliminary tests for now (10/10/2021 4pm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0b19e154",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "# Importing standard modules\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics import accuracy_score\n",
    "import lr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8f84598b",
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('../data/diabetes/diabetes_train.csv')\n",
    "test = pd.read_csv('../data/diabetes/diabetes_test.csv')\n",
    "valid = pd.read_csv('../data/diabetes/diabetes_val.csv')\n",
    "all_data = pd.concat([train, test, valid], axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "5210d0b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 9)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7ec35b11",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100000 Iterations\n",
      "Norm of gradient: 66.49749138475383\n",
      "\n",
      "Weights: [  55.77546839    7.10427188   -8.34629678   -1.56957379    2.78822622\n",
      "    2.42073196   55.22146839   -3.76922089 -323.93717164]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Test run with logistic regression model\n",
    "trainX=train.drop('Outcome',axis=1)\n",
    "trainY=train['Outcome']\n",
    "\n",
    "X=trainX.to_numpy()\n",
    "Y=trainY.to_numpy()\n",
    "\n",
    "model = lr.LogisticRegression(verbose=True, )\n",
    "yh = model.fit(X,Y).predict(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "1e2b0bcf",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LEARNING RATE: 0.0001 \n",
      "\n",
      "10000 Iterations\n",
      "Norm of gradient: 0.05549797321390251\n",
      "\n",
      "Weights: [ 0.10634008  0.01324276 -0.03067612 -0.00097639  0.00155382 -0.00562319\n",
      "  0.00618771 -0.00815136 -0.03614793]\n",
      "\n",
      "Accuracy Score: 0.7205882352941176\n",
      "90000 Iterations\n",
      "Norm of gradient: 0.03449646341252793\n",
      "\n",
      "Weights: [ 0.13165091  0.01419986 -0.02988331 -0.00113209  0.00151228 -0.00272609\n",
      "  0.05968231 -0.01166192 -0.31324052]\n",
      "\n",
      "Accuracy Score: 0.7205882352941176\n",
      "100000 Iterations\n",
      "Norm of gradient: 0.034307864937074266\n",
      "\n",
      "Weights: [ 0.13152847  0.014274   -0.02976018 -0.00115303  0.00150239 -0.00238826\n",
      "  0.06590202 -0.01156154 -0.34707329]\n",
      "\n",
      "Accuracy Score: 0.7205882352941176\n",
      "900000 Iterations\n",
      "Norm of gradient: 0.02240316810578086\n",
      "\n",
      "Weights: [ 1.27120605e-01  1.97367024e-02 -2.29781230e-02 -2.08817141e-03\n",
      "  8.95230229e-04  2.03927523e-02  3.56405128e-01 -4.82386649e-03\n",
      " -2.55614319e+00]\n",
      "\n",
      "Accuracy Score: 0.7352941176470589\n",
      "1000000 Iterations\n",
      "Norm of gradient: 0.021300042953086067\n",
      "\n",
      "Weights: [ 1.27088357e-01  2.03245049e-02 -2.24286357e-02 -2.14607917e-03\n",
      "  8.38344540e-04  2.27170193e-02  3.77169044e-01 -4.17037004e-03\n",
      " -2.77359450e+00]\n",
      "\n",
      "Accuracy Score: 0.7352941176470589\n",
      "9000000 Iterations\n",
      "Norm of gradient: 0.0015213069045572165\n",
      "\n",
      "Weights: [ 1.42456941e-01  3.49050348e-02 -1.27514189e-02 -3.45592724e-03\n",
      " -3.74930551e-04  8.27972263e-02  8.30683691e-01  9.43414819e-03\n",
      " -7.96611300e+00]\n",
      "\n",
      "Accuracy Score: 0.7647058823529411\n",
      "LEARNING RATE: 0.0009 \n",
      "\n",
      "10000 Iterations\n",
      "Norm of gradient: 64.7989049116022\n",
      "\n",
      "Weights: [ 0.55227814  0.06122602 -0.08793147 -0.0192026   0.03060825 -0.02031606\n",
      "  0.0530418  -0.0382594  -0.31861281]\n",
      "\n",
      "Accuracy Score: 0.5147058823529411\n",
      "90000 Iterations\n",
      "Norm of gradient: 64.53156152125361\n",
      "\n",
      "Weights: [ 5.68774174e-01  6.97103032e-02 -8.05935030e-02 -2.08891614e-02\n",
      "  3.10530635e-02 -4.96349023e-04  4.52538532e-01 -3.60259949e-02\n",
      " -2.73088992e+00]\n",
      "\n",
      "Accuracy Score: 0.5\n",
      "100000 Iterations\n",
      "Norm of gradient: 64.49917036723302\n",
      "\n",
      "Weights: [ 5.68417137e-01  7.07010976e-02 -7.97693286e-02 -2.09904628e-02\n",
      "  3.10596550e-02  1.94396125e-03  4.96961195e-01 -3.54275497e-02\n",
      " -3.01632642e+00]\n",
      "\n",
      "Accuracy Score: 0.5\n",
      "900000 Iterations\n",
      "Norm of gradient: 55.23746299167686\n",
      "\n",
      "Weights: [ 4.59476008e-01  1.07327829e-01 -3.83362396e-02 -1.59075673e-02\n",
      "  2.26753314e-02  1.43074772e-01  1.98924005e+00  1.82483163e-02\n",
      " -1.69638221e+01]\n",
      "\n",
      "Accuracy Score: 0.5882352941176471\n",
      "1000000 Iterations\n",
      "Norm of gradient: 54.04615746704828\n",
      "\n",
      "Weights: [ 4.50842487e-01  1.08233487e-01 -3.57692834e-02 -1.56926487e-02\n",
      "  2.18915646e-02  1.54766845e-01  2.02555528e+00  2.14490445e-02\n",
      " -1.77752000e+01]\n",
      "\n",
      "Accuracy Score: 0.6029411764705882\n",
      "9000000 Iterations\n",
      "Norm of gradient: 46.376581424098454\n",
      "\n",
      "Weights: [ 4.07152600e-01  1.09824564e-01 -2.21230162e-02 -1.60624260e-02\n",
      "  1.77144878e-02  2.26332389e-01  2.12580222e+00  3.60678359e-02\n",
      " -2.20031924e+01]\n",
      "\n",
      "Accuracy Score: 0.6176470588235294\n",
      "LEARNING RATE: 0.0002 \n",
      "\n",
      "10000 Iterations\n",
      "Norm of gradient: 0.03688780005515956\n",
      "\n",
      "Weights: [ 0.1270723   0.01360155 -0.03072393 -0.00098248  0.00157526 -0.00516212\n",
      "  0.01310928 -0.01147053 -0.07150879]\n",
      "\n",
      "Accuracy Score: 0.7205882352941176\n",
      "90000 Iterations\n",
      "Norm of gradient: 0.0328381067286037\n",
      "\n",
      "Weights: [ 1.30624877e-01  1.48650564e-02 -2.88188209e-02 -1.30896001e-03\n",
      "  1.42592630e-03  2.64255312e-04  1.12101440e-01 -1.07698993e-02\n",
      " -6.11586223e-01]\n",
      "\n",
      "Accuracy Score: 0.7205882352941176\n",
      "100000 Iterations\n",
      "Norm of gradient: 0.032481313341255064\n",
      "\n",
      "Weights: [ 0.13041944  0.01501208 -0.02859516 -0.00134487  0.00140752  0.0009135\n",
      "  0.12273586 -0.01057542 -0.67602891]\n",
      "\n",
      "Accuracy Score: 0.7205882352941176\n",
      "900000 Iterations\n",
      "Norm of gradient: 0.01463760406092056\n",
      "\n",
      "Weights: [ 1.28551365e-01  2.42382753e-02 -1.92482962e-02 -2.46601148e-03\n",
      "  4.81052937e-04  3.81713889e-02  5.00380139e-01 -9.94359700e-05\n",
      " -4.18299703e+00]\n",
      "\n",
      "Accuracy Score: 0.7647058823529411\n",
      "1000000 Iterations\n",
      "Norm of gradient: 0.013429351710347736\n",
      "\n",
      "Weights: [ 1.29152029e-01  2.50264215e-02 -1.86834650e-02 -2.52562870e-03\n",
      "  4.12691159e-04  4.13164885e-02  5.23867127e-01  6.70382786e-04\n",
      " -4.46242101e+00]\n",
      "\n",
      "Accuracy Score: 0.7794117647058824\n",
      "9000000 Iterations\n",
      "Norm of gradient: 0.0001629862241950338\n",
      "\n",
      "Weights: [ 1.45182742e-01  3.64126758e-02 -1.19739719e-02 -3.63848897e-03\n",
      " -4.86156961e-04  8.94292703e-02  8.79967465e-01  1.06648292e-02\n",
      " -8.50379293e+00]\n",
      "\n",
      "Accuracy Score: 0.75\n",
      "LEARNING RATE: 1e-05 \n",
      "\n",
      "10000 Iterations\n",
      "Norm of gradient: 0.19130443252157803\n",
      "\n",
      "Weights: [ 0.02109884  0.01231723 -0.03025673 -0.0015395   0.00145767 -0.0055575\n",
      "  0.0005087   0.00435942 -0.00378294]\n",
      "\n",
      "Accuracy Score: 0.6764705882352942\n",
      "90000 Iterations\n",
      "Norm of gradient: 0.06127993250119688\n",
      "\n",
      "Weights: [ 0.10183436  0.01317671 -0.0306577  -0.0009763   0.00154807 -0.00568044\n",
      "  0.00551293 -0.00742117 -0.03258723]\n",
      "\n",
      "Accuracy Score: 0.7205882352941176\n",
      "100000 Iterations\n",
      "Norm of gradient: 0.055497134703618625\n",
      "\n",
      "Weights: [ 0.106337    0.01324272 -0.0306761  -0.00097639  0.00155381 -0.00562321\n",
      "  0.00618773 -0.00815085 -0.03614793]\n",
      "\n",
      "Accuracy Score: 0.7205882352941176\n",
      "900000 Iterations\n",
      "Norm of gradient: 0.034496446747250484\n",
      "\n",
      "Weights: [ 0.13165091  0.01419986 -0.02988331 -0.00113209  0.00151228 -0.00272609\n",
      "  0.05968226 -0.01166192 -0.31324048]\n",
      "\n",
      "Accuracy Score: 0.7205882352941176\n",
      "1000000 Iterations\n",
      "Norm of gradient: 0.0343078484177042\n",
      "\n",
      "Weights: [ 0.13152847  0.014274   -0.02976018 -0.00115303  0.00150239 -0.00238826\n",
      "  0.06590197 -0.01156154 -0.34707324]\n",
      "\n",
      "Accuracy Score: 0.7205882352941176\n",
      "9000000 Iterations\n",
      "Norm of gradient: 0.022403160200082085\n",
      "\n",
      "Weights: [ 1.27120604e-01  1.97367012e-02 -2.29781241e-02 -2.08817115e-03\n",
      "  8.95230355e-04  2.03927478e-02  3.56405038e-01 -4.82386769e-03\n",
      " -2.55614273e+00]\n",
      "\n",
      "Accuracy Score: 0.7352941176470589\n",
      "LEARNING RATE: 0.001 \n",
      "\n",
      "10000 Iterations\n",
      "Norm of gradient: 65.27604148281094\n",
      "\n",
      "Weights: [ 0.60725578  0.06682714 -0.09697304 -0.02115336  0.03347322 -0.02011823\n",
      "  0.05880928 -0.04159531 -0.35273721]\n",
      "\n",
      "Accuracy Score: 0.5147058823529411\n",
      "90000 Iterations\n",
      "Norm of gradient: 65.02853125151216\n",
      "\n",
      "Weights: [ 6.32591980e-01  7.68834200e-02 -8.92396257e-02 -2.33270904e-02\n",
      "  3.45164149e-02  9.16621424e-04  4.99563092e-01 -4.02898071e-02\n",
      " -3.02661397e+00]\n",
      "\n",
      "Accuracy Score: 0.5\n",
      "100000 Iterations\n",
      "Norm of gradient: 65.00015626788687\n",
      "\n",
      "Weights: [ 0.63260215  0.0780354  -0.08835453 -0.02346052  0.03457066  0.00354448\n",
      "  0.54864778 -0.03971575 -3.34298196]\n",
      "\n",
      "Accuracy Score: 0.5\n",
      "900000 Iterations\n",
      "Norm of gradient: 56.0258541514638\n",
      "\n",
      "Weights: [ 5.15901835e-01  1.20491917e-01 -4.25686775e-02 -1.74861756e-02\n",
      "  2.55860454e-02  1.57346263e-01  2.22574396e+00  2.00118110e-02\n",
      " -1.89146207e+01]\n",
      "\n",
      "Accuracy Score: 0.5882352941176471\n",
      "1000000 Iterations\n",
      "Norm of gradient: 54.842098804213556\n",
      "\n",
      "Weights: [ 5.05983158e-01  1.21525388e-01 -3.96970355e-02 -1.72448126e-02\n",
      "  2.46974260e-02  1.70477435e-01  2.26760521e+00  2.36794237e-02\n",
      " -1.98271150e+01]\n",
      "\n",
      "Accuracy Score: 0.5882352941176471\n",
      "9000000 Iterations\n",
      "Norm of gradient: 47.21295263071595\n",
      "\n",
      "Weights: [ 4.57266500e-01  1.22980703e-01 -2.44747116e-02 -1.81317982e-02\n",
      "  2.00964150e-02  2.52091335e-01  2.35638000e+00  3.99396036e-02\n",
      " -2.45455082e+01]\n",
      "\n",
      "Accuracy Score: 0.6176470588235294\n",
      "LEARNING RATE: 0.0005 \n",
      "\n",
      "10000 Iterations\n",
      "Norm of gradient: 57.39313973539215\n",
      "\n",
      "Weights: [ 0.2848346   0.03421306 -0.04951734 -0.00869339  0.01535605 -0.01216415\n",
      "  0.03117524 -0.02063836 -0.17793798]\n",
      "\n",
      "Accuracy Score: 0.5147058823529411\n",
      "90000 Iterations\n",
      "Norm of gradient: 57.011400648121\n",
      "\n",
      "Weights: [ 2.84343930e-01  3.77477224e-02 -4.50299027e-02 -9.16336986e-03\n",
      "  1.49844816e-02  5.08436763e-04  2.65990483e-01 -1.75200051e-02\n",
      " -1.51399465e+00]\n",
      "\n",
      "Accuracy Score: 0.5294117647058824\n",
      "100000 Iterations\n",
      "Norm of gradient: 56.951204404589305\n",
      "\n",
      "Weights: [ 0.28361326  0.03817045 -0.04452775 -0.00919116  0.014931    0.0020215\n",
      "  0.29149103 -0.01703525 -1.67171382]\n",
      "\n",
      "Accuracy Score: 0.5294117647058824\n",
      "900000 Iterations\n",
      "Norm of gradient: 45.29304193805521\n",
      "\n",
      "Weights: [ 2.30643085e-01  5.42301210e-02 -2.18898079e-02 -7.65805539e-03\n",
      "  1.00313625e-02  8.34656839e-02  1.04898616e+00  9.75878078e-03\n",
      " -9.07639190e+00]\n",
      "\n",
      "Accuracy Score: 0.6470588235294118\n",
      "1000000 Iterations\n",
      "Norm of gradient: 43.991409349405856\n",
      "\n",
      "Weights: [ 2.27332264e-01  5.47581373e-02 -2.06088567e-02 -7.53475064e-03\n",
      "  9.61559567e-03  8.92489500e-02  1.07210344e+00  1.11680963e-02\n",
      " -9.49904362e+00]\n",
      "\n",
      "Accuracy Score: 0.6617647058823529\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9000000 Iterations\n",
      "Norm of gradient: 34.98848504133575\n",
      "\n",
      "Weights: [ 2.09305029e-01  5.70107269e-02 -1.34325514e-02 -6.97254908e-03\n",
      "  6.91086783e-03  1.24627387e-01  1.20803925e+00  1.85009852e-02\n",
      " -1.19250813e+01]\n",
      "\n",
      "Accuracy Score: 0.7352941176470589\n"
     ]
    }
   ],
   "source": [
    "# Function to find convergent solution of gradient descent as a function of learning-rate and maximum iterations\n",
    "\"\"\"\n",
    "Best one so far:\n",
    "                    L = 0.0002\n",
    "                    I = 9e6\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "def optimize(max_iter, learning_rate, pred_data):\n",
    "    \n",
    "    # Input data, features and binary labels column\n",
    "    Xin = train.drop('Outcome',axis=1).to_numpy()\n",
    "    Yin = train['Outcome'].to_numpy()\n",
    "    \n",
    "    # Prediction data, validation set\n",
    "    Xp = pred_data.drop('Outcome',axis=1).to_numpy()\n",
    "    Yp = pred_data['Outcome'].to_numpy().ravel()\n",
    "    \n",
    "    # Iterate through the input parameters\n",
    "    for l in learning_rate:\n",
    "        \n",
    "        for m in max_iter:\n",
    "            \n",
    "            #print(\"MAX ITERATIONS: \", m)\n",
    "            print(f'LEARNING RATE: {l} \\n')\n",
    "            model = lr.LogisticRegression(verbose=True, add_bias=True, learning_rate=l, max_iters=m)\n",
    "            yh = model.fit(Xin,Yin).predict(Xp)\n",
    "            T = []\n",
    "            T.append(yh)\n",
    "        \n",
    "            # Decision Boundary\n",
    "            prediction = []\n",
    "            for x in np.array(T).ravel():\n",
    "                if x < 0.5: prediction.append(0)\n",
    "                else: prediction.append(1)\n",
    "\n",
    "            #print(T)\n",
    "            #print(prediction)\n",
    "            #print(Yp)\n",
    "            print(\"Accuracy Score:\", accuracy_score(Yp,np.array(prediction).ravel()))\n",
    "    \n",
    "mi = [1e4,9e4,1e5,9e5,1e6,9e6]\n",
    "learn = [0.0001,0.0009,0.0002,0.00001,0.001,0.0005]\n",
    "\n",
    "optimize(max_iter=mi, learning_rate=learn, pred_data=test)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
